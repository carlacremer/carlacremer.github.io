---
layout: page
permalink: /research/
---

#### research interests | keywords

##### computational cognitive science  | epistemic risk | distributed algorithmic technology assessments 

##### global catastrophic risk assessment | foresight 

#### academic research publications

[Democratising Risk](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3995225) In Search of a Methodology to Study Existential Risk, 2021 preprint in SSRN

[Deep Limitations?](https://link.springer.com/article/10.1007/s13748-021-00239-1) Examining Expert Disagreement over Deep Learning, 2021 Published in Progress in Artificial Intelligence

[Artificial Canaries](https://www.ijimai.org/journal/sites/default/files/2021-02/ijimai_6_5_10.pdf) Early Warning Signs for Anticipatory and Democratic Governance of AI, 2021, Cremer and Whittlestone in the International Journal of Interactive Multimedia and Artificial Intelligence and best paper award at [EPAI 2020](https://dmip.webs.upv.es/EPAI2020/).

#### other writing 

[Advice to UN High-level Panel on Digital Cooperation](https://www.cser.ac.uk/news/advice-un-high-level-panel-digital-cooperation/) co-authored with Dr Luke Kemp, Peter Cihon, Matthijs Michiel Maas, Haydn Belfield, Dr Seán Ó hÉigeartaigh, Jade Leung 

Contributions to report on [Tackling threats to informed decision-making in democratic societies.](https://www.turing.ac.uk/research/publications/tackling-threats-informed-decision-making-democratic-societies)

Contributions to report on [epistemic security](https://www.turing.ac.uk/sites/default/files/2020-10/epistemic-security-report_final.pdf)

Critique of Effective Altruism - [Objections to Value Alignment](https://forum.effectivealtruism.org/posts/DxfpGi9hwvwLCf5iQ/objections-to-value-alignment-between-effective-altruists), forum prize in July 2020

#### misc activities | sample 

I sometimes start projects, like [ZAIA, the Zurich AI Alignment](https://www.zurich-ai-alignment.com/discussion-group), (in 2018 together with [Matthew Raatz](http://amid.fish/)), mentor in reserach fellowships such as e.g. [Tianxia](https://www.tian-xia.com/), give talks for e.g. the [Oxford AI Safety Society](https://twitter.com/OxfordAI/status/1521139105127669761?s=20) and contribute to or consulte organisations like [AI Objectives Institute](https://ai.objectives.institute/blog/ai-and-the-transformation-of-capitalism) or the [Cooperative AI Foundation](https://www.cooperativeai.com/)


