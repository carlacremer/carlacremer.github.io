---
layout: page
title: Research
permalink: /research/
---

#### my research interests - keywords

*computational neuroscience, epistemic risk, distributed algorithmic technology assessments, global catastrophic risk



#### academic research publications

[Democratising Risk](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3995225) In Search of a Methodology to Study Existential Risk, 2021 preprint in SSRN

[Deep Limitations?](https://link.springer.com/article/10.1007/s13748-021-00239-1) Examining Expert Disagreement over Deep Learning, 2021 Published in Progress in Artificial Intelligence

[Artificial Canaries](https://www.ijimai.org/journal/sites/default/files/2021-02/ijimai_6_5_10.pdf) Early Warning Signs for Anticipatory and Democratic Governance of AI, 2021, Cremer and Whittlestone in the International Journal of Interactive Multimedia and Artificial Intelligence and best paper award at [EPAI 2020](https://dmip.webs.upv.es/EPAI2020/).



#### other writing 

Critique of Effective Altruism - [Objections to Value Alignment](https://forum.effectivealtruism.org/posts/DxfpGi9hwvwLCf5iQ/objections-to-value-alignment-between-effective-altruists), forum prize in July 2020

[Advice to UN High-level Panel on Digital Cooperation](https://www.cser.ac.uk/news/advice-un-high-level-panel-digital-cooperation/) co-authored with Dr Luke Kemp, Peter Cihon, Matthijs Michiel Maas, Haydn Belfield, Dr Seán Ó hÉigeartaigh, Jade Leung 

Contributions to report on [Tackling threats to informed decision-making in democratic societies.](https://www.turing.ac.uk/research/publications/tackling-threats-informed-decision-making-democratic-societies)


#### media

Video Podcast: Interviewed by Sanat Singhal on matters like the [politics of extinction risk and existential ethics, power and effective altruism](https://youtu.be/vL1LmW_FJkI)

[![Podcast](https://img.youtube.com/vi/vL1LmW_FJkI/0.jpg)](https://www.youtube.com/watch?v=vL1LmW_FJkI)


#### misc

I founded [ZAIA, The Zurich AI Alignment](https://www.zurich-ai-alignment.com/discussion-group) reading group, together with Matthew Raatz, mentored in reserach fellowships like [Tianxia](https://www.tian-xia.com/), have given talks for e.g. the [Oxford AI Safety Society](https://twitter.com/OxfordAI/status/1521139105127669761?s=20) and consulted organisations like [AI Objectives Institute](https://ai.objectives.institute/blog/ai-and-the-transformation-of-capitalism) or [Cooperative AI Foundation](https://www.cooperativeai.com/)


